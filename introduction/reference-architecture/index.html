<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="What is the purpose of the event-driven reference architecture?"><meta name=author content="Jerome Boyer"><link href=https://ibm-cloud-architecture.github.com/refarch-eda/introduction/reference-architecture/ rel=canonical><link rel=icon href=../../assets/favicon.png><meta name=generator content="mkdocs-1.3.1, mkdocs-material-8.4.1"><title>Reference Architectures - IBM Automation - Event-driven Solution - Sharing knowledge</title><link rel=stylesheet href=../../assets/stylesheets/main.69437709.min.css><link rel=stylesheet href=../../assets/stylesheets/palette.cbb835fc.min.css><meta name=theme-color content=#000000><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><link rel=stylesheet href=../../extra.css><script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=black data-md-color-accent=indigo> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#from-soa-to-eda-and-meet-in-the-middle class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <header class="md-header md-header--lifted" data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=../.. title="IBM Automation - Event-driven Solution - Sharing knowledge" class="md-header__button md-logo" aria-label="IBM Automation - Event-driven Solution - Sharing knowledge" data-md-component=logo> <img src=../../images/es-icon.png alt=logo> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> IBM Automation - Event-driven Solution - Sharing knowledge </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> Reference Architectures </span> </div> </div> </div> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg> </label> <nav class=md-search__options aria-label=Search> <a href=javascript:void(0) class="md-search__icon md-icon" aria-label=Share data-clipboard data-clipboard-text data-md-component=search-share tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7 0-.24-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91 1.61 0 2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08Z"/></svg> </a> <button type=reset class="md-search__icon md-icon" aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/ibm-cloud-architecture/refarch-eda title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.1.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg> </div> <div class=md-source__repository> ibm-cloud-architecture/refarch-eda </div> </a> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../.. title="IBM Automation - Event-driven Solution - Sharing knowledge" class="md-nav__button md-logo" aria-label="IBM Automation - Event-driven Solution - Sharing knowledge" data-md-component=logo> <img src=../../images/es-icon.png alt=logo> </a> IBM Automation - Event-driven Solution - Sharing knowledge </label> <div class=md-nav__source> <a href=https://github.com/ibm-cloud-architecture/refarch-eda title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.1.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg> </div> <div class=md-source__repository> ibm-cloud-architecture/refarch-eda </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../.. class=md-nav__link> Home </a> </li> <li class=md-nav__item> <a href=../../news/ class=md-nav__link> What's new </a> </li> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_3 type=checkbox id=__nav_3 checked> <label class=md-nav__link for=__nav_3> Introduction <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Introduction data-md-level=1> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> Introduction </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../overview/ class=md-nav__link> Overview </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" data-md-toggle=toc type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> Reference Architecture <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> Reference Architecture </a> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#from-soa-to-eda-and-meet-in-the-middle class=md-nav__link> From SOA to EDA and meet in the middle </a> </li> <li class=md-nav__item> <a href=#event-driven-architecture class=md-nav__link> Event Driven Architecture </a> </li> <li class=md-nav__item> <a href=#kappa-architecture class=md-nav__link> Kappa architecture </a> </li> <li class=md-nav__item> <a href=#agile-integration-and-eda class=md-nav__link> Agile integration and EDA </a> </li> <li class=md-nav__item> <a href=#integrating-with-ibm-automation-products class=md-nav__link> Integrating with IBM automation products </a> <nav class=md-nav aria-label="Integrating with IBM automation products"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#process-mining-integration class=md-nav__link> Process Mining integration </a> </li> <li class=md-nav__item> <a href=#integration-with-decision-service class=md-nav__link> Integration with decision service </a> </li> <li class=md-nav__item> <a href=#business-process-integration class=md-nav__link> Business process integration </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#integration-with-analytics-and-machine-learning class=md-nav__link> Integration with analytics and machine learning </a> <nav class=md-nav aria-label="Integration with analytics and machine learning"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#getting-the-data-for-the-data-scientist class=md-nav__link> Getting the data for the data scientist: </a> </li> <li class=md-nav__item> <a href=#data-scientist-workbench class=md-nav__link> Data scientist workbench </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#modern-data-lake class=md-nav__link> Modern Data Lake </a> </li> <li class=md-nav__item> <a href=#legacy-integration class=md-nav__link> Legacy Integration </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../usecases/ class=md-nav__link> Business Use Cases </a> </li> <li class=md-nav__item> <a href=../target-audiences/ class=md-nav__link> Target Audiences </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_4 type=checkbox id=__nav_4> <label class=md-nav__link for=__nav_4> Learning Journey <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Learning Journey" data-md-level=1> <label class=md-nav__title for=__nav_4> <span class="md-nav__icon md-icon"></span> Learning Journey </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../journey/101/ class=md-nav__link> Get started (101 content) </a> </li> <li class=md-nav__item> <a href=../../journey/201/ class=md-nav__link> Deeper dive (201 content) </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_5 type=checkbox id=__nav_5> <label class=md-nav__link for=__nav_5> Concepts <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Concepts data-md-level=1> <label class=md-nav__title for=__nav_5> <span class="md-nav__icon md-icon"></span> Concepts </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../concepts/terms-and-definitions/ class=md-nav__link> Terms & Definitions </a> </li> <li class=md-nav__item> <a href=../../concepts/integration/ class=md-nav__link> Agile Integration </a> </li> <li class=md-nav__item> <a href=../../concepts/events-versus-messages/ class=md-nav__link> Event streaming versus Queuing </a> </li> <li class=md-nav__item> <a href=../../concepts/fit-to-purpose/ class=md-nav__link> Fit for purpose </a> </li> <li class=md-nav__item> <a href=../../concepts/model/ class=md-nav__link> Devising the data models </a> </li> <li class=md-nav__item> <a href=../../concepts/flow-architectures/ class=md-nav__link> Flow Architecture </a> </li> <li class=md-nav__item> <a href=../../concepts/service-mesh/ class=md-nav__link> Service mesh </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_6 type=checkbox id=__nav_6> <label class=md-nav__link for=__nav_6> Advantages of EDA <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Advantages of EDA" data-md-level=1> <label class=md-nav__title for=__nav_6> <span class="md-nav__icon md-icon"></span> Advantages of EDA </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../advantages/microservice/ class=md-nav__link> Microservice decoupling </a> </li> <li class=md-nav__item> <a href=../../advantages/reactive/ class=md-nav__link> Reactive systems </a> </li> <li class=md-nav__item> <a href=../../advantages/resiliency/ class=md-nav__link> Resiliency </a> </li> <li class=md-nav__item> <a href=../../advantages/scalability/ class=md-nav__link> Scalability </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_7 type=checkbox id=__nav_7> <label class=md-nav__link for=__nav_7> Patterns in EDA <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Patterns in EDA" data-md-level=1> <label class=md-nav__title for=__nav_7> <span class="md-nav__icon md-icon"></span> Patterns in EDA </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../patterns/intro/ class=md-nav__link> Introduction </a> </li> <li class=md-nav__item> <a href=../../patterns/event-sourcing/ class=md-nav__link> Event Sourcing </a> </li> <li class=md-nav__item> <a href=../../patterns/cqrs/ class=md-nav__link> CQRS </a> </li> <li class=md-nav__item> <a href=../../patterns/saga/ class=md-nav__link> Saga </a> </li> <li class=md-nav__item> <a href=../../patterns/dlq/ class=md-nav__link> Dead Letter Queue </a> </li> <li class=md-nav__item> <a href=../../patterns/topic-replication/ class=md-nav__link> Topic Replication </a> </li> <li class=md-nav__item> <a href=../../patterns/data-pipeline/ class=md-nav__link> Data Intensive App </a> </li> <li class=md-nav__item> <a href=../../patterns/realtime-analytics/ class=md-nav__link> Near real-time analytics </a> </li> <li class=md-nav__item> <a href=../../patterns/api-mgt/ class=md-nav__link> API management </a> </li> <li class=md-nav__item> <a href=../../patterns/cep/ class=md-nav__link> Situational decision </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_8 type=checkbox id=__nav_8> <label class=md-nav__link for=__nav_8> Methodology <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Methodology data-md-level=1> <label class=md-nav__title for=__nav_8> <span class="md-nav__icon md-icon"></span> Methodology </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../methodology/event-storming/ class=md-nav__link> Event Storming </a> </li> <li class=md-nav__item> <a href=../../methodology/domain-driven-design/ class=md-nav__link> Domain-Driven Design </a> </li> <li class=md-nav__item> <a href=../../methodology/data-intensive/ class=md-nav__link> Data Intensive App Development </a> </li> <li class=md-nav__item> <a href=../../methodology/data-lineage/ class=md-nav__link> Data lineage </a> </li> <li class=md-nav__item> <a href=../../methodology/governance/ class=md-nav__link> Governance </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_9 type=checkbox id=__nav_9> <label class=md-nav__link for=__nav_9> Technology <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Technology data-md-level=1> <label class=md-nav__title for=__nav_9> <span class="md-nav__icon md-icon"></span> Technology </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../technology/kafka-overview/ class=md-nav__link> Kafka Overview </a> </li> <li class=md-nav__item> <a href=../../technology/event-streams/ class=md-nav__link> Event Streams </a> </li> <li class=md-nav__item> <a href=https://ibm-cloud-architecture.github.io/eda-tech-academy/demo/ class=md-nav__link> Event Streams Demo Script </a> </li> <li class=md-nav__item> <a href=../../technology/faq/ class=md-nav__link> Kafka FAQ </a> </li> <li class=md-nav__item> <a href=../../technology/mq/ class=md-nav__link> MQ in EDA context </a> </li> <li class=md-nav__item> <a href=../../technology/kafka-producers/ class=md-nav__link> Kafka Producers </a> </li> <li class=md-nav__item> <a href=../../technology/kafka-consumers/ class=md-nav__link> Kafka Consumers </a> </li> <li class=md-nav__item> <a href=../../technology/avro-schemas/ class=md-nav__link> Avro Schema </a> </li> <li class=md-nav__item> <a href=../../technology/advanced-kafka/ class=md-nav__link> Advanced Concepts </a> </li> <li class=md-nav__item> <a href=../../technology/kafka-streams/ class=md-nav__link> Kafka Streams </a> </li> <li class=md-nav__item> <a href=../../technology/kafka-connect/ class=md-nav__link> Kafka Connect </a> </li> <li class=md-nav__item> <a href=../../technology/event-streams/es-maas/security/ class=md-nav__link> Kafka security </a> </li> <li class=md-nav__item> <a href=../../technology/kafka-monitoring/ class=md-nav__link> Kafka Monitoring </a> </li> <li class=md-nav__item> <a href=../../technology/kafka-mirrormaker/ class=md-nav__link> Mirror Maker 2 </a> </li> <li class=md-nav__item> <a href=../../technology/security/ class=md-nav__link> Security </a> </li> <li class=md-nav__item> <a href=../../technology/flink/ class=md-nav__link> Apache Flink </a> </li> <li class=md-nav__item> <a href=../../technology/spring/ class=md-nav__link> Spring cloud </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_10 type=checkbox id=__nav_10> <label class=md-nav__link for=__nav_10> Use Cases <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Use Cases" data-md-level=1> <label class=md-nav__title for=__nav_10> <span class="md-nav__icon md-icon"></span> Use Cases </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../use-cases/gitops/ class=md-nav__link> Event-driven solution GitOps </a> </li> <li class=md-nav__item> <a href=../../technology/event-streams/es-cp4i/ class=md-nav__link> Deploy Event-Streams </a> </li> <li class=md-nav__item> <a href=../../use-cases/connect-s3/ class=md-nav__link> Kafka Connect - S3 </a> </li> <li class=md-nav__item> <a href=../../use-cases/connect-cos/ class=md-nav__link> Kafka Connect - COS </a> </li> <li class=md-nav__item> <a href=../../use-cases/connect-jdbc/ class=md-nav__link> Kafka Connect - jdbc </a> </li> <li class=md-nav__item> <a href=../../use-cases/connect-mq/ class=md-nav__link> Kafka Connect - MQ </a> </li> <li class=md-nav__item> <a href=../../use-cases/connect-rabbitmq/ class=md-nav__link> Kafka Connect - Rabbitmq </a> </li> <li class=md-nav__item> <a href=../../use-cases/kafka-streams/ class=md-nav__link> Kafka Streams labs </a> </li> <li class=md-nav__item> <a href=../../use-cases/db2-debezium/ class=md-nav__link> DB2 - CDC Debezium - Outbox </a> </li> <li class=md-nav__item> <a href=../../use-cases/kafka-mm2/ class=md-nav__link> Mirror maker 2 labs </a> </li> <li class=md-nav__item> <a href=../../use-cases/schema-registry-on-cloud/ class=md-nav__link> Schema registry ES on Cloud </a> </li> <li class=md-nav__item> <a href=../../use-cases/schema-registry-on-ocp/ class=md-nav__link> Schema registry </a> </li> <li class=md-nav__item> <a href=../../use-cases/monitoring-on-cloud/ class=md-nav__link> Monitoring ES on Cloud </a> </li> <li class=md-nav__item> <a href=../../use-cases/monitoring-on-ocp/ class=md-nav__link> Monitoring ES </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_11 type=checkbox id=__nav_11> <label class=md-nav__link for=__nav_11> Scenarios <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Scenarios data-md-level=1> <label class=md-nav__title for=__nav_11> <span class="md-nav__icon md-icon"></span> Scenarios </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../scenarios/overview/ class=md-nav__link> Overview </a> </li> <li class=md-nav__item> <a href=https://ibm-cloud-architecture.github.io/refarch-kc/ class=md-nav__link> Reefer Shipment Solution </a> </li> <li class=md-nav__item> <a href=https://ibm-cloud-architecture.github.io/vaccine-solution-main/ class=md-nav__link> Vaccine at Scale </a> </li> <li class=md-nav__item> <a href=https://ibm-cloud-architecture.github.io/eda-rt-inventory-gitops class=md-nav__link> Near real-time Inventory </a> </li> <li class=md-nav__item> <a href=../../scenarios/saga-orchestration/ class=md-nav__link> SAGA with MQ Orchestration </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../additional-reading/ class=md-nav__link> Additional reading </a> </li> <li class=md-nav__item> <a href=../../contribute/ class=md-nav__link> Contribute to this Site </a> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#from-soa-to-eda-and-meet-in-the-middle class=md-nav__link> From SOA to EDA and meet in the middle </a> </li> <li class=md-nav__item> <a href=#event-driven-architecture class=md-nav__link> Event Driven Architecture </a> </li> <li class=md-nav__item> <a href=#kappa-architecture class=md-nav__link> Kappa architecture </a> </li> <li class=md-nav__item> <a href=#agile-integration-and-eda class=md-nav__link> Agile integration and EDA </a> </li> <li class=md-nav__item> <a href=#integrating-with-ibm-automation-products class=md-nav__link> Integrating with IBM automation products </a> <nav class=md-nav aria-label="Integrating with IBM automation products"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#process-mining-integration class=md-nav__link> Process Mining integration </a> </li> <li class=md-nav__item> <a href=#integration-with-decision-service class=md-nav__link> Integration with decision service </a> </li> <li class=md-nav__item> <a href=#business-process-integration class=md-nav__link> Business process integration </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#integration-with-analytics-and-machine-learning class=md-nav__link> Integration with analytics and machine learning </a> <nav class=md-nav aria-label="Integration with analytics and machine learning"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#getting-the-data-for-the-data-scientist class=md-nav__link> Getting the data for the data scientist: </a> </li> <li class=md-nav__item> <a href=#data-scientist-workbench class=md-nav__link> Data scientist workbench </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#modern-data-lake class=md-nav__link> Modern Data Lake </a> </li> <li class=md-nav__item> <a href=#legacy-integration class=md-nav__link> Legacy Integration </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <a href=https://github.com/ibm-cloud-architecture/refarch-eda/edit/master/docs/introduction/reference-architecture/index.md title="Edit this page" class="md-content__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25Z"/></svg> </a> <h1>Reference Architecture</h1> <p>Updated 05/27/2022</p> <p>We defined the starting point for a cloud-native event-driven architecture to be that it supports at least the following important capabilities:</p> <ul> <li>Being able to communicate asynchronously between components to improve elasticity, resilience and responsiveness. </li> <li>Support exactly one delivery of messages in a asynchronous request/response interactions</li> <li>Publish messages as facts or events as immutable records to an append log so subscribers can consume them at any point of time.</li> <li>Processing streams of events to derive real time insight/intelligence.</li> <li>Providing communication mechanism between event-driven microservices and functions.</li> </ul> <h2 id=from-soa-to-eda-and-meet-in-the-middle>From SOA to EDA and meet in the middle<a class=headerlink href=#from-soa-to-eda-and-meet-in-the-middle title="Permanent link">&para;</a></h2> <p>We do not need to present Service Oriented Architecture as a way to organize modern application... Well modern was started in 2003. In 2006, Enterprise Service Bus was at the center of thee SOA adoption with API exposure, mediation flows, and service gateway. ESB is a pattern but also a product.</p> <p><img alt src=images/soa-esb-centric.png></p> <p>Business services exposes APIs, defined with WSDL and the protocol is XML heavy with SOAP. The rich set of specification in the <a href=https://en.wikipedia.org/wiki/List_of_web_service_specifications>ws-*</a> helps to address complex business applications, where application can dynamically searching for API producer, bind to the end point, and then call the service.</p> <p>SOA is still a core structure of IT architecture today.</p> <p>Two major characteristics of IT architecture are the scalability and the coupling with others. With the way most of SOA services are done is by pulling data from other services or call operation on API to make something done (delegation, command patterns). The dependencies between service via the service contract, and the heavy use of XML have put some limit to the scalability and coupling dimensions.</p> <p>EDA was already proposed, in 2004, as a way to address scalability, as illustrated by this figure below:</p> <p><img alt src=images/soa-eda-venn.png></p> <p>EDA helps to decouple communication and contract between services, move to push data as immutable facts amd async communication.</p> <p>New applications started to be implemented, early 2010s, to address scalability need. RESTful and JSON are becoming ubiquituous technology, protocols to use. This is a neat evolution from SOAP and XML, but the applications exposing API with OpenAPI specification are still point to point, and the data pull is still the pattern to get access to data. The <a href=../../advantages/reactive/#overview>reactive manifesto</a> is also promoting sound principles to make modern applications more responsive, resilient and elastics therefore adopting messages. </p> <p>EDA and SOA do not have to compete, but are complementary addressing different kind of problem. Combined together they provide innovative business solutions to problems we never thought could be solved:</p> <ul> <li>Event driven business process</li> <li>near real-time analytics</li> <li>real-time flow analysis</li> <li>complex event processing with time window based business rules</li> <li>services act as event source or sink</li> <li>event trigger services</li> <li>service to process events</li> </ul> <h2 id=event-driven-architecture>Event Driven Architecture<a class=headerlink href=#event-driven-architecture title="Permanent link">&para;</a></h2> <p>Event-driven architecture is not something new, and it is not just about Kafka. As listed in previous section EDA at the core has to support asynchronous communication between application in two major semantics:</p> <ul> <li>request/response with exactly one delivery with no data lost, when a component is asking another component to do something for it. This approach is to address long running transaction or business process and enforce using queuing technology.</li> <li>deliver facts about its own data to an immutable log so other components can derive something about it. This is a pub/sub model with strong time decoupling.</li> </ul> <p>To support these EDA has a message as a service capability as cluster of message brokers. The brokers provides the connectivity between the other components: </p> <p><img alt=hl-arch-ra src=images/hl-arch-ra.png></p> <p>Where:</p> <ul> <li><a href=../../concepts/terms-and-definitions/#event-sources>Event sources</a>: generates events from sources such as IoT devices, web apps, mobile apps, mainframe applications, change data capture agents...</li> <li><strong>Mainframe queuing apps</strong> are source for messages using the IBM MQ replication feature to expose mainframe messages to the cloud native MQ broker and so to the cloud native microservices. The strong consistency is kept but facts about the business transactions are propagated to the eventual consistency world.</li> <li> <p><strong>Messaging as a service</strong> is the core backbone of the architecture to support any type of asynchronous communication:</p> <ul> <li><a href=https://www.ibm.com/cloud/mq>IBM MQ</a>: delivers the exatly one delivery, strong consistency and supports queuing and pub/sub protocol. MQ brokers in cluster support high availability cross data centers to build event-mesh. IBM MQ will be the unique technology to guarantee the end to end message availability.</li> <li><a href=https://www.ibm.com/cloud/event-streams>IBM Event Streams</a>: provides an event backbone supporting Pub/Sub protocol only, with immutable append log. Event Streams is based on <a href=https://kafka.apache.org/ >Apache Kafka</a> and can run on-premise or as <a href=https://cloud.ibm.com/catalog/services/event-streams>managed services</a></li> </ul> </li> <li> <p><strong>Reactive cloud native applications</strong>: The top row represents modern applications which adopt the <a href=https://www.reactivemanifesto.org/ >reactive manifesto</a> as a way to be resilient, elastic and message driven. To reduce microservice to microservice dependency and reduce coupling, modern microservices are <a href=../../concepts/terms-and-definitions/#microservices>event-driven</a> and implemented with reactive framework (e.g. vert.x )and reactive messaging (e.g. microprofile 3.0 reactive messaging). Some of those applications can be function and serverless apps, meaning scaling to zero and being able to wake-up on event arrival. Finally it is important to note that business process applications running in BPM can be triggered by event arrival, can generate intermediate events, and can generate events at the process completion. Those business events are important to shared with other applications to being expose to event backbone.</p> </li> <li>The adoption of Kafka as a way to support event backbone capability, also means that records can be saved for a long period of time, but it is relevant to be able to persist those records or an aggregate view of those records to a data lake or a set of s3 buckets. So most of EDA has sink connectors to data lake. </li> <li>The governance of these asynchronous applications is becoming a major requirement when the adoption of such architecture grows. AsyncAPI, combined with schema registry helps defining the intercommunication contracts. While most of the event-driven microservices are exposing Open APIs, enforced by API gateway, it is now possible to do the same enforcement and monitoring with the <a href=https://community.ibm.com/community/user/integration/blogs/dale-lane1/2021/04/12/a-demo-of-event-endpoint-management>event endpoint gateway</a>.</li> <li>The bottom row supports new types of application for <strong>data streaming</strong>: the first set of applications are for getting business insight of the event sequencing by looking at event patterns as supported by the complex event processing engine (Apache Flink), and the second type are to process near-real time analytics to compute analytical processing across multiple event streams. The technologies of choice are <a href=../../technology/flink>Apache Flink</a> and <a href=https://www.ibm.com/cloud/sql-query>IBM SQL query</a>. Those applications are also cloud native, and run in container deployable inside Kubernetes clusters.</li> <li><a href=https://pinot.apache.org/ >Apache Pinot</a> bring Realtime distributed OLAP datastore to support fast indexing, scale horizontally, OLAP queries for user-facing analytics, and application queries. Support low latency &lt; 1s with millions events per s. Pinot can also be used for anomaly detection.</li> </ul> <p>In term of physical deployment on OpenShift the following figures illustrates a multi zone deployment, with Event Streams and MQ Operators deployed and managing five Event Streams brokers Cluster, and three MQ brokers</p> <p><img alt src=images/maas-ocp.png></p> <p>This reference architecture is illustrated in the implementation of different solutions: </p> <ul> <li><a href=https://ibm-cloud-architecture.github.io/refarch-kc/ >The shipping goods oversea solution</a> </li> <li><a href=https://github.com/ibm-cloud-architecture/eda-rt-inventory-gitops/ >The real-time inventory</a></li> <li>The <a href=https://ibm-cloud-architecture.github.io/vaccine-solution-main/ >vaccine at scale</a> solution.</li> </ul> <h2 id=kappa-architecture>Kappa architecture<a class=headerlink href=#kappa-architecture title="Permanent link">&para;</a></h2> <p>The Kappa Architecture is a software architecture used for processing streaming data. The main premise behind the Kappa Architecture is that we can perform both real-time and batch processing, especially for analytics, with a single technology stack.</p> <p><img alt src=images/kappa-ra.png></p> <ul> <li>Data in motion includes append-log based topic, and Apache Kafka acts as the store for the streaming data.</li> <li>Streaming processing is the practice of taking action on a series of data at the time the data is created. It can be done with different technologies like <a href=../../technology/kafka-streams/ >Kafka Streams</a>, Apache Sparks streaming, <a href=../../technology/flink/ >Apache Flink</a>, Redis streaming, or <a href=https://hazelcast.com/ >Hazelcast</a>.</li> <li>The serving layer is where OLAP queries and searches are done, most of the time with indexing and other advanced capabilities are needed to offer excellent response time, high throughput and low latency. </li> </ul> <p>It is a simpler alternative to the Lambda Architecture – as all data is treated as if it were a stream. Both architectures entail the storage of historical data to enable large-scale analytics.</p> <h2 id=agile-integration-and-eda>Agile integration and EDA<a class=headerlink href=#agile-integration-and-eda title="Permanent link">&para;</a></h2> <p>Event driven architecture is a complement of the overall integration reference architecture as <a href=https://www.ibm.com/cloud/architecture/architectures/modern-integration/overview>presented in IBM Cloud architecture center</a>.</p> <p>In this section, we want to summarize some of the important aspects of agile integration and how some of the technologies delivered as part of IBM Cloud Pak for Integration are used when doing application modernization with event-driven microservice. </p> <p>The main agile integration concepts as presented in detail in the <a href=https://www.ibm.com/cloud/integration/agile-integration>IBM cloud on agile integration article</a> can be summarized as:</p> <ul> <li>Empower extended teams to create integrations, leveraging a complete set of integration styles and capabilities to increase overall team productivity.</li> <li>Agile integration includes container-based, decentralized, microservices-aligned approach for integrating solutions</li> <li>Existing centralized integration architectures, based on ESB pattern, cannot support the demand, in term of team reactivity and scalability at the internet level.</li> <li>ESB pattern provides standardized synchronous connectivity to back-end systems typically over web services (SOAP based). ESB formed a single infrastructure for the whole enterprise, with tens or hundreds of integrations installed on a production server cluster.</li> <li>A single, centralized ESB certainly simplifies consistency and governance of implementation.</li> <li>Interface maintenance is expensive.</li> <li>Any deployment to the shared servers runs the risk of destabilizing existing critical interfaces.</li> <li>SOA encounters the issue of getting the funding at the enterprise wide program to maintain reusable interface.</li> <li>Integration teams are becoming the bottleneck instead of being enabler.</li> <li>SOA is about real-time integration between applications, whereas a microservices architecture is about how the applications are built internally.</li> <li> <p>Microservice enables greater agility by being:</p> </li> <li> <p>small enough to be understood completely by their owning team and changed independently</p> </li> <li>elastic to scale horizontally</li> <li>resilient with changes to one microservice will not affect others at runtime</li> </ul> <p>The following diagram illustrates the agile integration modernization transition from a centralized ESB type of architecture, and breaking integration into smaller pieces to make them more agile and more scalable.</p> <p><img alt src=images/agile_integration.png></p> <p>In this modernization process, development team can introduce API Management to improve decoupling between consumers and providers ultimately moving to a decentralized approach where each team can manage their own integration.</p> <ul> <li> <p>Three aspects to agile integration:</p> <ol> <li><strong>Decentralized integration ownership</strong>: give application teams more control over the creation and exposure of their own integration exposed as APIs, or messages</li> <li><strong>Fine-grained integration deployment</strong> to separate integration, scalable independently. Changes to individual integration flows can be automatically rebuilt and deployed independently of other flows to enable safer application of changes and maximize speed to production.</li> <li><strong>Cloud-native integration infrastructure</strong> to improve productivity, operational consistency and portability for both applications and integration</li> </ol> </li> </ul> <p><a href=../../concepts/integration/ >Read more on those concepts in this note</a></p> <h2 id=integrating-with-ibm-automation-products>Integrating with IBM automation products<a class=headerlink href=#integrating-with-ibm-automation-products title="Permanent link">&para;</a></h2> <p>EDA is becoming the new foundation to expose business services, and business applications. Combined with SOA and microservices architecture, it exposes messaging as a services to be used by automation products, like Robot Process Automation bots, Process Mining, Chat Bots, and the more traditional workflow engines and decision engines.</p> <p>Those products are leveraging data in the event backbone or in the queues to do their own processing. But they are also event producer. We can build a new digital automation reference architecture, based on event-driven and messaging communication like in the figure below:</p> <p><img alt src=images/automation-eda.png></p> <p>On the top row, the capabilities include:</p> <ul> <li>Existing business applications, and SOA services: most of them are J2EE applications running on application servers, such as WebSphere Application Server, some are mainframe applications using transactions and strong consistency. Those applications will integrate new microservices or webapps using JSON / RESTful resources exposed via an API Gateway, or will use MQ queue when asynchronous protocol is used.</li> <li>New single page applications are also accessing business services via the API gateway, and use HTTP (RESTful) protocol. Those single page applications can be developed using <a href="https://www.ibm.com/docs/en/cloud-paks/1.0?topic=software-business-automation-application">IBM Business Automation Application</a>.</li> <li>Existing business process applications, running within BPM servers, may have been designed to be triggered by <a href="https://www.ibm.com/docs/en/baw/20.x?topic=events-event-types">message arrival</a>, and may be able to <a href="https://www.ibm.com/docs/en/baw/20.x?topic=mme-using-intermediate-message-events-message-end-events-send-messages">emit intermediate events</a> within a task execution. IBM BPM, for example, has JMS queue integration to consume and publish messages to JMS queues, which should be defined in IBM MQ Brokers.</li> </ul> <blockquote> <p>A business process is the set of combined activities defined as an orchestrated workflow within the business to achieve a business goal which uses system services or refers work to process workers</p> </blockquote> <ul> <li>New workflow can be entirely event-driven, and designed to act on event arrival to trigger process instances or task instances. They are also supported by Case management products which are well suited to address unstructured execution path, where next steps are not pre-determined.</li> <li>As stated above, new microservices are becoming message-driven and are using queues for async request / response communication, they ask someone to participate into their business process. And they publish state changes via events to pub/sub topics.</li> <li>Consumers can use <a href="https://www.ibm.com/docs/en/cloud-paks/cp-integration/2021.1?topic=socializing-your-kafka-event-sources">Event End point management</a> to access to topics and process the data, do data mapping and data transformation for long persistence into data lake.</li> <li>The key integration between EDA and automation is by adding stateful agents that are aggregating, correlating, and computing the next best actions. Those actions can be to trigger a human workflow, initiate a RPA bot, call one or more decision services. Those stateful agents can use complex event processing engines, rule engines, and integrate with predictive scoring. A lot of new use-cases are covered by these capabilities like fraud detection, know your customer, product recommendations...</li> <li>The predictive scoring models are defined in AI workbench tool, like Watson Studio or Cloud Pak for Data. The data used to develop the model come from data lake, existing datawarehouse but also the messaging service, like Kafka topics.</li> <li>The AI workbench includes tools to do data analysis and visualization, to build training and test sets from any datasources and in particular topics, and tp develop models. Models are integrated to streaming analytics component.</li> <li>With this extended architecture, most of business applications are generating events, directly by code, or by adopting less intruisive techniques like change data capture agents. Those events are representing facts about the busienss entities and the processes implemented cross microservices and applications. This is were Process Mining product are very important to plug into this data stream. </li> </ul> <h3 id=process-mining-integration>Process Mining integration<a class=headerlink href=#process-mining-integration title="Permanent link">&para;</a></h3> <p>Process mining is a tool to analyze process execution logs or data. The consumption vehicle are cvs files. When adopting EDA, data in the business process may be initiated by a single page application, sent to Kafka as events, cosumed by a human centric, long running, process application, processed by a data streaming application in Flink... Each element of this 'Saga' transaction will event time based fact about the data and so about the process. Then it will make sense to analyze those data. The integration will look like in the figure below, where data processing prepares the expected CVS format, and persists file in scalable, secured long storage like S3 buckets (IBM Cloud Object Storage), and then business analysts loads those files into Process Mining to conduct their analysis: </p> <p><img alt src=images/es-pm-itg.png></p> <h3 id=integration-with-decision-service>Integration with decision service<a class=headerlink href=#integration-with-decision-service title="Permanent link">&para;</a></h3> <p>The figure below illustrates an integration between data produces on Event Streams, consumed by Apache Flink data streaming jobs which detect fraud or business situation which needs to be processed by business rule logic in IBM Operational Decision Management to compute the next best action:</p> <p><img alt src=images/flink-ds-itg.png></p> <h3 id=business-process-integration>Business process integration<a class=headerlink href=#business-process-integration title="Permanent link">&para;</a></h3> <p>BPMN has multiple event constructs to support receiving events, generating intermediate events, and sending closing events.</p> <h2 id=integration-with-analytics-and-machine-learning>Integration with analytics and machine learning<a class=headerlink href=#integration-with-analytics-and-machine-learning title="Permanent link">&para;</a></h2> <p>The extended architecture extends the basic EDA reference architecture with concepts showing how data science, artificial intelligence and machine learning can be incorporated into an event-driven solution. The following diagram illustrats the event sources on the left injecting events to topics where green components are consuming from. Those components apply filtering, compute aggregates and stateful operation with time window based rules. Some of those components can include training scoring model, to do for example anomaly detection. The model is built with data scientist workbench tool, like Watson Studio.</p> <p><img alt=2 src=images/hl-arch-rt-analytics.png></p> <p>The starting point for data scientists to be able to derive machine learning models or analyze data for trends and behaviors is the existence of the data in a form that they can be consumed. For real-time intelligent solutions, data scientists typically inspect event histories and decision or action records from a system. Then, they reduce this data to some simplified model that scores new event data as it arrives.</p> <h3 id=getting-the-data-for-the-data-scientist>Getting the data for the data scientist:<a class=headerlink href=#getting-the-data-for-the-data-scientist title="Permanent link">&para;</a></h3> <p>With near real-time event streams, the challenge is in handling unbounded data or a continuous flow of events. To make this consumable for the data scientist you need to capture the relevant data and store it so that it can be pulled into the analysis and model-building process as required.</p> <p>Following our event-driven reference architecture the event stream would be a Kafka topic on the event backbone. From here there are two possibilities for making that event data available and consumable to the data scientist:</p> <ul> <li>The event stream or event log can be accessed directly through Kafka and pulled into the analysis process</li> <li>The event stream can be pre-processed by the streaming analytics system and stored for future use in the analysis process. You have a choice of store type to use. Within public IBM cloud object storage <a href=https://www.ibm.com/cloud/object-storage>Cloud Object Store</a> can be used as a cost-effective historical store.</li> </ul> <p>Both approaches are valid, pre-processing through streaming analytics provides opportunity for greater manipulation of the data, or storing data over time windows for complex event processing. However, the more interesting distinction is where you use a predictive (ML model) to score arriving events or stream data in real time. In this case you may use streaming analytics to extract and save the event data for analysis, model building, and model training and also for scoring (executing) a derived model in line in the real time against arriving event data.</p> <ul> <li>The event and decision or action data is made available in cloud object storage for model building through streaming analytics.</li> <li>Models may be developed by tuning and parameter fitting, standard form fitting, classification techniques, and text analytics methods.</li> <li>Increasingly artificial intelligence (AI) and machine learning (ML) frameworks are used to discover and train useful predictive models as an alternative to parameterizing existing model types manually.</li> <li>These techniques lead to process and data flows where the predictive model is trained offline using event histories from the event and the decision or action store possibly augmented with some supervisory outcome labelling, as illustrated by the paths from the <code>Event Backbone</code> and <code>Stream Processing</code> store into <code>Learn/Analyze</code>.</li> <li>A model trained in this way includes some “scoring” API that can be invoked with fresh event data to generate a model-based prediction for future behavior and event properties of that specific context.</li> <li>The scoring function is then easily reincorporated into the streaming analytics processing to generate predictions and insights.</li> </ul> <p>These combined techniques can lead to the creation of near real-time intelligent applications:</p> <ol> <li>Event-driven architecture</li> <li>Identification of predictive insights using event storming methodology</li> <li>Developing models for these insights using machine learning</li> <li>Near real-time scoring of the insight models using a streaming analytics processing framework</li> </ol> <p>These are scalable easily extensible, and adaptable applications responding in near real time to new situations. There are easily extended to build out and evolve from an initial minimal viable product (MVP) because of the loose coupling in the event-driven architecture, , and streams process domains.</p> <h3 id=data-scientist-workbench>Data scientist workbench<a class=headerlink href=#data-scientist-workbench title="Permanent link">&para;</a></h3> <p>To complete the extended architecture for integration with analytics and machine learning, consider the toolset and frameworks that the data scientist can use to derive the models. <a href=https://www.ibm.com/marketplace/watson-studio>Watson Studio</a> provides tools for data scientists, application developers, and subject matter experts to collaboratively and easily work with data to build and train models at scale.</p> <p>For more information see <a href=https://dataplatform.cloud.ibm.com/docs/content/getting-started/overview-ws.html>Getting started</a> with Watson Studio.</p> <h2 id=modern-data-lake>Modern Data Lake<a class=headerlink href=#modern-data-lake title="Permanent link">&para;</a></h2> <p>One of the standard architecture to build data lake is the lambda architecture with data injection, stream processing, batch processing to data store and then queries as part of the service layer. It is designed to handle massive quantities of data by taking advantage of both batch and stream processing methods. Lambda architecture depends on a data model with an append-only, immutable data source that serves as a system of record. The batch layer precomputes results using a distributed processing system that can handle very large quantities of data. Output from the batch and speed layers are stored in the serving layer, which responds to ad-hoc queries by returning precomputed views or building views from the processed data.</p> <p>The following figure is an enhancement of the lambda architecture with the adoption of Kafka as event backbone for data pipeline and source of truth and streaming processing to support real time analytics and streaming queries.</p> <p><img alt=3 src=images/data-lake-1.png></p> <p>On the left the different data sources, injected using different protocols like MQTT, HTTP, or Kafka Connect... The business applications are supported by different microservices that are exposed by APIs and event-driven. The APIs is managed by API management product. Business events are produced as facts about the business entities, and persisted in the append log of kafka topic. Transactional data can be injected from MQ queues to Kafka topic, via MQ connectors. </p> <p>The data platform offers a set of capabilities to expose data for consumers like Data Science workbench (Watson Studio) via virtualization and data connections. The data are cataloged and governed to ensure integrity and visibility. The storage can be block based, document oriented or table oriented.</p> <p>Batch queries and map reduce can address huge data raw, while streaming queries can support real time aggregates and analytics.</p> <h2 id=legacy-integration>Legacy Integration<a class=headerlink href=#legacy-integration title="Permanent link">&para;</a></h2> <p>While you create new digital business applications as self-contained systems, you likely need to integrate legacy apps and databases into the event-driven system. Two ways of coming directly into the event-driven architecture are as follows:</p> <ol> <li> <p>Where legacy applications are connected with MQ. You can connect directly from MQ to the Kafka in the event backbone. See <a href=https://ibm.github.io/event-streams/connecting/mq/ >IBM Event Streams getting started with MQ article</a>. The major idea here is to leverage the transactionality support of MQ, so writing to the databased and to the queue happen in the same transaction:</p> <p><img alt=3 src=images/hl-arch-data-pipe-mq.png></p> </li> <li> <p>Where databases support the capture of changes to data, you can publish changes as events to Kafka and hence into the event infrastructure. This could leverage the <a href=../../patterns/intro/#transactional-outbox>outbox pattern</a> where events are prepared by the application and written, in the same transaction as the other tables, and read by the CDC capture agent.</p> <p><img alt=4 src=images/hl-arch-data-pipe-cdc.png></p> </li> </ol> <p>Or use an efficient CDC product to get the change data capture at the transaction level. IBM offers the best CDC product on the market, (<a href=https://www.ibm.com/support/knowledgecenter/SSTRGZ_11.4.0/com.ibm.idr.frontend.doc/pv_welcome.html>InfoSphere Data Replication 11.4.0</a>), with subsecond average latency and support full transactional semantics with exactly once consumption. It includes an <a href=https://www.ibm.com/support/knowledgecenter/SSTRGZ_11.4.0/com.ibm.cdcdoc.cdckafka.doc/concepts/systemrequirements.html>efficient Kafka integration</a>. </p> <p>One of the challenges of basic CDC products, is the replication per table pattern, leads to retry to rebuild the transaction integrity using kafka stream to join data from multiple topics. The <a href=https://www.ibm.com/support/knowledgecenter/SSTRGZ_11.4.0/com.ibm.cdcdoc.cdckafka.doc/concepts/kafkatcc.html>TCC (Transactionally consistent consumer) technology</a> allows Kafka replication to have semantics similar to a relational database. This dramatically increases the types of business logic that can be implemented. Developer can recreate the order of operations in source transactions across multiple Kafka topics and partitions and consume Kafka records that are free of duplicates by including the Kafka transactionally consistent consumer library in your Java applications. TCC allows:</p> <ul> <li>Elimination of any duplicates, even in abnormal termination scenarios</li> <li>Reconstruction of exact transaction order, despite those transactions having been performance optimized and applied out of order to Kafka</li> <li>Reconstruction of exact operation order within a transaction, despite said operations having been applied to different topics and/or partitions. This is not offered by default Kafka's "exactly once" functionality</li> <li>Ability for hundreds+ producers to participate in a single transaction. Kafka's implementation has one producer create all messages for a transaction, despite those messages going to different topics.</li> <li>Provides a unique bookmark, so that downstream applications can check-point and resume exactly where they last left off if they fail.</li> </ul> <p><em>We recommend listeing to this presentation from Shawn Roberston - IBM, on <a href=https://www.confluent.io/kafka-summit-sf18/a-solution-for-leveraging-kafka-to-provide-end-to-end-acid-transactions/ >A Solution for Leveraging Kafka to Provide End-to-End ACID Transactions</a></em></p> <p>The second, very important, feature is on the producer side, with the Kafka custom operation processor (or KCOP) infrastructure. KCOP helps you to control over the Kafka producer records that are written to Kafka topics in response to insert, update, and delete operations that occur on source database tables. It allows a user to programmatically dictate the exact key an byte values of the message written to Kafka. Therefore any individual row transformation message encoding format is achievable. Out of the box it includes Avro, CSV, JSON message encoding formats. It is possible to perform column level RSA encryption on certain values before writing. It also permits enriching of the message with additional annotation if needed. Developers have the complete choice over how data is represented. Eg. Can write data in Kafka Compaction compliant format with deletes being represented as Kafka tombstones or can write the content of the message being deleted.</p> <p>It also supports Kafka Header fields for efficient downstream routing without the need for immediate de-serialization. The KCOP allows a user to determine how many messages are written to Kafka in response to a source operation, the content of the messages, and their destination.</p> <ul> <li>Allows for filtering based on column values.</li> <li>Allows for writing the entire row with sensitive data to highly restricted topics and a subset of the columns to wider shared topics.</li> <li>Allows for writing the same message in two different formats to two different topics. Useful in environments where some consuming applications want JSON, others prefer Avro, both can be produced in parallel if desired.</li> <li>Allows for sending special flags to a monitoring topic. Eg. when a transaction exceeds $500, in addition to the regular message, a special topic is written to notifying of the large value transaction</li> </ul> <p>The two diagrams above, illustrate a common architecture for data pipeline, using event backbone, where the data is transformed into different data model, that can be consumed by components that act on those data, and move the data document into data lake for big data processing.</p> <p>Finally it is important to note that the deployment of the event streams, CDC can be colocated in the mainframe to reduce operation and runtime cost. It also reduces complexity. In the following diagram, event stream brokers are deployed on OpenShift on Linux on Z and the CDC servers on Linux too.</p> <p><img alt=6 src=images/es-on-z-deployment.png></p> <p>This architecture pattern try to reduce the MIPs utilization on the mainframe to the minimum by still ensuring data pipeline, with transactional integrity. </p> <ul> <li>Quality of Service – autoscaling / balancing between Linux nodes, Resilience.</li> <li>Latency - memory speed (Network -&gt; HiperSocket, with memory speed and bandwidth)</li> <li>Reduce MIPS (avoid Authentication-TLS overhead on z/OS as no network traffic is encrypted)</li> <li>Avoid network spend / management / maintenance between servers</li> <li>Improved QoS for the Kafka service – inherits Z platform (Event Streams is the only Kafka variant currently supported on Linix on Z) </li> <li>Reduced complexity / management cost</li> <li>Reduced latency / network infrastructure (apply – Kafka hop is now in memory) – avoids need for encryption </li> </ul> <p>The CDC server uses <a href=https://www.ibm.com/support/knowledgecenter/SSTRGZ_11.4.0/com.ibm.cdcdoc.cdckafka.doc/concepts/kafkatcc.html>Transaction Capture Consumer</a> to keep transaction integrity while publishing to kafka topic. CICS Business events are mechanism for declaratively emitting event from CICS routines.</p> </article> </div> </div> </main> <footer class=md-footer> <nav class="md-footer__inner md-grid" aria-label=Footer> <a href=../overview/ class="md-footer__link md-footer__link--prev" aria-label="Previous: Overview" rel=prev> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg> </div> <div class=md-footer__title> <div class=md-ellipsis> <span class=md-footer__direction> Previous </span> Overview </div> </div> </a> <a href=../usecases/ class="md-footer__link md-footer__link--next" aria-label="Next: Business Use Cases" rel=next> <div class=md-footer__title> <div class=md-ellipsis> <span class=md-footer__direction> Next </span> Business Use Cases </div> </div> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"/></svg> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright © 2022 IBM </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> <div class=md-social> <a href=https://github.com/ibm-cloud-architecture target=_blank rel=noopener title=github.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><!-- Font Awesome Free 6.1.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg> </a> <a href=https://twitter.com/agileitarchitecture target=_blank rel=noopener title=twitter.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 6.1.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"base": "../..", "features": ["content.code.annotate", "content.tooltips", "navigation.instant", "navigation.tabs.sticky", "search.highlight", "search.share", "search.suggest", "toc.follow"], "search": "../../assets/javascripts/workers/search.ecf98df9.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version.title": "Select version"}}</script> <script src=../../assets/javascripts/bundle.9c69f0bc.min.js></script> </body> </html>