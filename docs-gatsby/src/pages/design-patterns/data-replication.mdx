---
title: Data replication in context of EDA
description: Data replication in context of EDA
---

As an introduction to the scope of the data replication in the context of distributed system, we encourage to read our summary in [this article](https://ibm-cloud-architecture.github.io/refarch-data-ai-analytics/data/data-replication/).

In this section we are going to address the data replication in the context of Kafka using IBM Geo Replication and Kafka Mirror Maker 2.

## Problem statement

We suppose we need to replicate data in Kafka topics between different Kafka clusters running in different availability zones or data centers. There are multiple motivations for such replication. We can list at least the followings:

* Support disaster recovery, using different data centers to replicate microservice generated data in an active - passive mode.
* Move data closer to end user to improve performance and latency, this is more an active - active model, where the same microservices are deployed on the different data centers.
* The need to build on-premise data aggregation or data lake layer to perform batch analytics jobs from data gathered from different remote environments.
* Isolate secure data from on-premise cluster, with data encryption and data transformation to remove personal identifiable information, but still exchange such data between environments.

We are proposing two environments:

* One running a local, on-premise cluster using Kafka 2.4 open source packaging, like Strimzi vanilla Kafka or Red Hat AMQ Streams, and IBM Event Streams on Cloud.

![Replication with mirror maker](images/replication-2.png)

In the figure above, Mirror Maker 2.0 is used to do bi-directional replication between topics defined in both cluster. The grey topic is replicated from right to left, and the Mirror Maker 2.0 source connector runs close to the target cluster, the left cluster. The light blue topic is replicated from left to right by the second Mirror Maker 2.0. Microservices on both data centers can consume messages from both topics.

* One running Event streams on Openshift on-premise, and using Geo-replication to Event Streams on IBM cloud.

![Replication with geo replication](images/replication-1.png)

Then we want to address two main scenarios:

* [Active - passive](#active-passive), which addresses more a disaster recovery approach where consumers reconnect to a new cluster after the first one fails.
* [Active - active](#active-active) deployments where participant clusters have producers and consumers and some topics are replicated so the messages are processed by different consumers

But first we need to review the new replication capability introduced with Kafka 2.4, the [Mirror Maker 2.0](https://cwiki.apache.org/confluence/display/KAFKA/KIP-382%3A+MirrorMaker+2.0).

## Mirror Maker 2.0

Mirror maker 2.0 is a new feature as part of Kafka 2.4 to support data replication between clusters. It is based on Kafka Connect framework, and it supports data and metadata replication, like the topic configuration, the offset and the consumer checkpoints are synchronously replicated to the target cluster.

Mirror maker uses the cluster name or identifier as prefix for topic, and uses the concept of source topic and target topic. The specification is described in detail in [this KIP 382](https://cwiki.apache.org/confluence/display/KAFKA/KIP-382%3A+MirrorMaker+2.0#KIP-382:MirrorMaker2.0-RemoteTopics,Partitions).

To test the tool, we can use the Strimzi Kafka latest docker image deployed on Openshift cluster (We address Strimzi deployment in [this note](../deployments/strimzi/deploy/)). For mirror maker 2.0, the deployment descriptor are in the [Strimzi project](https://strimzi.io/downloads/) under the `examples/kafka-mirror-maker-2` folder (we have a copy of this yaml file, prepared for our replication, in the deployments/strimzi folder of this project).

To define the clusters and topic configuration we use a properties file. One simple example to replicate from IBM Cloud Event streams to Kafka on premise is in the folder [deployments/strimzi/es-mirror-maker.properties](https://github.com/ibm-cloud-architecture/refarch-eda/blob/master/deployments/strimzi/es-mirror-maker.properties)

Using the same kafka image we can start a mirror maker container with:

```properties
clusters = source, target
source.bootstrap.servers = my-cluster-kafka-bootstrap-jb-kafka-strimzi.gse-eda-demos-fa9ee67c9ab6a7791435450358e564cc-0001.us-east.containers.appdomain.cloud:443
source.security.protocol=SSL
source.ssl.truststore.password=password
source.ssl.truststore.location=/home/truststore.jks
target.bootstrap.servers = kafka1:9092
# enable and configure individual replication flows
source->target.enabled = true
source->target.topics = test
```

```bash
./connect-mirror-maker.sh /home/strimzi.properties 
```
When Mirror maker starts it will create some topics on source cluster to manage the offsets and topic metadata:

```
mm2-configs.target.internal                                   1            3
mm2-offset-syncs.target.internal                              1            3
mm2-offsets.target.internal                                   25           3
mm2-status.target.internal                                    5            3
```

And on the target cluster:

```
__consumer_offsets
heartbeats
mm2-configs.source.internal
mm2-offsets.source.internal
mm2-status.source.internal
source.checkpoints.internal
source.heartbeats
source.test
```

The `source.test` topic is the replicated `test` topic from the source cluster.

![](images/mm-k-connect.png)

## Active - Passive

To support active - passive, one site has producers and consumers on local topics, and topic data are replicated on active cluster without online consumers


## Active - Active

* producers, deployed on IBM cloud within Openshift, send messages to Event streams on cloud, on the 'reeferTelemetries` topic. The explanation of the telemetry simulator producer deployment is done [here.](https://ibm-cloud-architecture.github.io/refarch-reefer-ml/infuse/simul-app/#prepare-for-kubernetes-deployment)
